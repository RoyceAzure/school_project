{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dected_ROI(frame, width, height ,limit):   #保留frame [limit:height-limit, limit: width-limit] 範圍內的值  其餘弄成黑色\n",
    "#     margin = limit//2\n",
    "    mask=np.zeros([height,width],dtype=np.uint8) \n",
    "    mask[limit:height-limit, limit: width-limit] = 255\n",
    "    image = cv2.bitwise_and(frame, frame, mask=mask) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detection_filter(detection_object):\n",
    "    CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "    \"sofa\", \"train\", \"tvmonitor\"]\n",
    "#當偵測到4個物體時，detection.shape[2] = 4，所以這裡是偵測到的個數\n",
    "    #這是detections.shape = (1, 1, 4, 7)\n",
    "    need_delete_index=[]\n",
    "\n",
    "    for i in np.arange(0,detection_object.shape[0]):\n",
    "        # extract the confidence (i.e., probability) associated\n",
    "        # with the prediction\n",
    "        confidence = detection_object[i, 2]\n",
    "        # extract the index of the class label from the\n",
    "        # detections list\n",
    "        idx = int(detection_object[i, 1])\n",
    "\n",
    "        #[0.         1.         0.30299687 0.07226107 0.03428271 0.6716727  0.9734354 ]\n",
    "        #[0]=?  [1]=idx [2]=confidence [3:7] = corrdinate \n",
    "        # filter out weak detections by requiring a minimum\n",
    "        # confidence\n",
    "        \n",
    "        if confidence < 0.6 or CLASSES[idx] != \"person\" :\n",
    "            #print(\"delete:\")\n",
    "            #print(detection_object[i,:])\n",
    "            need_delete_index.append(i)\n",
    "\n",
    "    #print(\"need_delete_index\")\n",
    "    #print(need_delete_index)\n",
    "    detection_object = np.delete(detection_object, need_delete_index, axis=0)\n",
    "\n",
    "    return detection_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_background(frame, vname):\n",
    "    path = 'save/background_{}.jpg'.format(vname)\n",
    "    cv2.imwrite(path, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def main_func_predict(video_path, dected_per_frame = 30, method = 'dlib', \n",
    "                      seconds_proid = 10):\n",
    "    getFrame = False\n",
    "    video_name = re.findall(r'/(\\w+)\\.mp4$', video_path)[0]\n",
    "    fm = filed_tool_v2.All_filed(video_name, seconds_proid)\n",
    "\n",
    "    param = {'fm' : fm} \n",
    "\n",
    "    def draw_rectangle(event,x,y,flags,param):  #setMouseCallback要用的\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            param['fm'].updateI((x,y))\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            param['fm'].updateFiled((x,y))\n",
    "#     param['fm'].testdata()\n",
    "\n",
    "\n",
    "    cv2.namedWindow(winname='my_drawing')\n",
    "    cv2.setMouseCallback('my_drawing',draw_rectangle,param)\n",
    "    \n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    limit = int(max(width, height)/10)\n",
    "#     width = 500\n",
    "#     height = 1000\n",
    "    dis_threshold = max(height, width)/10\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    net = cv2.dnn.readNetFromCaffe('mobilenet_ssd_caffe/MobileNetSSD_deploy.prototxt', 'mobilenet_ssd_caffe/MobileNetSSD_deploy.caffemodel')\n",
    "    \n",
    "    write_path = 'result/{}.mp4'.format(video_name)\n",
    "#     videoWriter = cv2.VideoWriter(write_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, (width, height))\n",
    "    total_frame = 0\n",
    "    sec = 0\n",
    "    ft = Filter.Filter(width, height) \n",
    "    dt = draw_tool_v2.draw_tool()\n",
    "    print(\"width:{}\".format(width))\n",
    "    print(\"height:{}\".format(height))\n",
    "    trks = mutiTracker.Trackers(dist_thresh = 50, max_frames_to_skip = 2, \n",
    "                                max_trace_length = 600, \n",
    "                                leave_limit = limit/2, \n",
    "                                frame_info = (width, height),\n",
    "                               video_name = video_name,\n",
    "                               time_proid = seconds_proid)\n",
    "    peroid_count = False\n",
    "    while(cap.isOpened()):\n",
    "        ret,frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"end of the video file...\")\n",
    "            break\n",
    "#         frame = imutils.resize(frame,width=500)\n",
    "        \n",
    "        if method == 'dlib':\n",
    "            dected_frame = frame\n",
    "            dected_frame = cv2.cvtColor(dected_frame, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            dected_frame = frame\n",
    "            \n",
    "        tensor_frame = dected_ROI(frame, width, height ,limit)\n",
    "        \n",
    "        if len(trks.get_trackers()) != 0:\n",
    "            trks.predict_update(dected_frame)\n",
    "            trackers = trks.get_trackers()\n",
    "            for tracker in trackers:\n",
    "                cen = tracker.centroid\n",
    "                ID = tracker.track_id\n",
    "                box = tracker.bbox\n",
    "                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]),(0, 255, 0), 1)\n",
    "                num = cen[0]\n",
    "                amend = num% 10\n",
    "                cv2.putText(frame, str(ID), (cen[0]-(amend*1), cen[1]), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            trks.checked_leaved()\n",
    "            \n",
    "        if total_frame % dected_per_frame == 0:\n",
    "            print(\"dected!!!!!!!!!\")\n",
    "            blob = cv2.dnn.blobFromImage(tensor_frame, 0.007843, (width, height), 127.5)\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "            detections = np.squeeze(detections,axis=None)\n",
    "            if(len(detections.shape)==1): #如果維度太低，改變為適當的維度\n",
    "                detections = np.expand_dims(detections, axis=0)\n",
    "            filtered_detections = detection_filter(detections)\n",
    "            rects = list()\n",
    "            for i in range (0,filtered_detections.shape[0]):\n",
    "                bounding_box = filtered_detections[i, 3:7] * np.array([width, height, width, height])\n",
    "                (startX, startY, endX, endY) = bounding_box.astype(\"int\")\n",
    "                rects.append((startX, startY, endX, endY))\n",
    "#             rects, total_count, adds = ft.predict_Filter_people_box(np.squeeze(boxes), \n",
    "#                                                                     np.squeeze(classes).astype(np.int32),\n",
    "#                                                                     np.squeeze(scores))\n",
    "\n",
    "            if not getFrame:\n",
    "                get_background(frame, video_name)\n",
    "                getFrame = True\n",
    "            for (startX, startY, endX, endY) in rects:\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 0, 255), 2)\n",
    "\n",
    "            trks.detect_Update(rects, dected_frame, method)\n",
    "\n",
    "\n",
    "        fm.dected_per_frame(trks.get_trackers(), frame)\n",
    "        if fm.is_has_filed():\n",
    "            dt.draw_filed(frame, fm.get_all_filed())\n",
    "#         videoWriter.write(frame)\n",
    "        cv2.imshow('my_drawing', frame)\n",
    "        total_frame+=1\n",
    "\n",
    "        sec = int(round(total_frame/fps,3))\n",
    "#                 print(\"sec{}\".format(sec))\n",
    "\n",
    "        if sec % seconds_proid == 0 and int(sec)!=0 and not peroid_count:\n",
    "            time_proid = \"{}_{}\".format(int(sec-seconds_proid), int(sec))\n",
    "            trks.time_proid = time_proid\n",
    "            fm.time_proid = time_proid\n",
    "            trks.save_total_people()\n",
    "            fm.save_all_count()\n",
    "            peroid_count = True\n",
    "        elif sec % seconds_proid != 0:\n",
    "            peroid_count = False\n",
    "        print('-'*50)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    fm.final_save_all()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1f9295886d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils_v2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiled_tool_v2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw_tool_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, re, imutils, glob, os, cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils_v2 import filed_tool_v2, label_map_util, Filter, draw_tool_v2\n",
    "from trackers import mutiTracker, correlation_tracker, kalman_filter, opencv_trackers\n",
    "\n",
    "# detection_graph, category_index =set_model('rfcn_resnet101_coco_11_06_2017')\n",
    "main_func_predict('videos/v1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# import time, re, imutils, glob, os, cv2\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from utils_v2 import filed_tool_v2, label_map_util, Filter, draw_tool_v2\n",
    "# from trackers import mutiTracker, correlation_tracker, kalman_filter, opencv_trackers\n",
    "\n",
    "# detection_graph, category_index =set_model('faster_rcnn_resnet101_coco_11_06_2017')\n",
    "# videos = ['v21','v22','v23','v24','v25','v26','v27','v28','v29','v30','v31','v32','v33','v34','v35']\n",
    "# for video in videos:\n",
    "#     path = 'videos/{}.mp4'.format(video)\n",
    "#     main_func_predict(detection_graph,category_index, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in d:\\anaconda\\envs\\school_pro_env\\lib\\site-packages (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
